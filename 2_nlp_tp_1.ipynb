{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application NLP : Univers Musical de Charles Aznavour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\DELL\n",
      "[nltk_data]     3420\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\DELL\n",
      "[nltk_data]     3420\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to C:\\Users\\DELL\n",
      "[nltk_data]     3420\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to C:\\Users\\DELL\n",
      "[nltk_data]     3420\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ======= Importation des bibliothèques =======\n",
    "#!pip install spacy nltk textblob langdetect vaderSentiment deep-translator textblob_fr pandas numpy scikit-learn\n",
    "\n",
    "# NLP (Traitement du langage naturel)\n",
    "import spacy  \n",
    "import nltk  \n",
    "from nltk.corpus import stopwords  \n",
    "from nltk.tokenize import word_tokenize  \n",
    "from nltk.stem import SnowballStemmer  \n",
    "from nltk.sentiment import SentimentIntensityAnalyzer  \n",
    "from textblob import TextBlob\n",
    "from langdetect import detect  \n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer \n",
    "import subprocess\n",
    "from deep_translator import GoogleTranslator\n",
    "from textblob import TextBlob\n",
    "from textblob_fr import PatternTagger, PatternAnalyzer\n",
    "import langid\n",
    "\n",
    "# Manipulation des données\n",
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "from sklearn.preprocessing import OneHotEncoder  \n",
    "\n",
    "# Traitement de texte et Regex\n",
    "import re  \n",
    "import unicodedata  \n",
    "\n",
    "# ======= Téléchargement des ressources NLTK si nécessaire =======\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement de la base de donnée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A changer\n",
    "artist = \"Charles Aznavour\"\n",
    "file_name = f\"{artist.strip().replace(' ', '_').lower()}.csv\"\n",
    "base = pd.read_csv(file_name)\n",
    "base = base[base['paroles'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>paroles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Blue Like The Blue Of Your Eyes</td>\n",
       "      <td>https://paroles2chansons.lemonde.fr/paroles-ch...</td>\n",
       "      <td>A blue like the blue of your eyes When they're...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>À chacun sa bohème</td>\n",
       "      <td>https://paroles2chansons.lemonde.fr/paroles-ch...</td>\n",
       "      <td>Je vous parle d'un temps La bohème Je vous par...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A Ma Fille</td>\n",
       "      <td>https://paroles2chansons.lemonde.fr/paroles-ch...</td>\n",
       "      <td>Je sais qu’un jour viendra Car la vie le comma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>À ma manière</td>\n",
       "      <td>https://paroles2chansons.lemonde.fr/paroles-ch...</td>\n",
       "      <td>Le jour Qui pour toujours Verra le lourd Ridea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A mia foglia</td>\n",
       "      <td>https://paroles2chansons.lemonde.fr/paroles-ch...</td>\n",
       "      <td>Il giorno arriverà che temo, ma che attendo, I...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               title  \\\n",
       "0  A Blue Like The Blue Of Your Eyes   \n",
       "1                 À chacun sa bohème   \n",
       "5                         A Ma Fille   \n",
       "6                       À ma manière   \n",
       "7                       A mia foglia   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://paroles2chansons.lemonde.fr/paroles-ch...   \n",
       "1  https://paroles2chansons.lemonde.fr/paroles-ch...   \n",
       "5  https://paroles2chansons.lemonde.fr/paroles-ch...   \n",
       "6  https://paroles2chansons.lemonde.fr/paroles-ch...   \n",
       "7  https://paroles2chansons.lemonde.fr/paroles-ch...   \n",
       "\n",
       "                                             paroles  \n",
       "0  A blue like the blue of your eyes When they're...  \n",
       "1  Je vous parle d'un temps La bohème Je vous par...  \n",
       "5  Je sais qu’un jour viendra Car la vie le comma...  \n",
       "6  Le jour Qui pour toujours Verra le lourd Ridea...  \n",
       "7  Il giorno arriverà che temo, ma che attendo, I...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(693, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chargement des modèles spaCy pour différentes langues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les modèles sont déjà installés.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    nlp_fr = spacy.load('fr_core_news_sm')\n",
    "    nlp_en = spacy.load(\"en_core_web_sm\")\n",
    "    print(\"Les modèles sont déjà installés.\")\n",
    "except OSError:\n",
    "    print(\"Les modèles ne sont pas installés. Installation en cours...\")\n",
    "    subprocess.run([\"python\", \"-m\", \"spacy\", \"download\", \"en_core_web_sm\"])\n",
    "    subprocess.run([\"python\", \"-m\", \"spacy\", \"download\", \"fr_core_web_sm\"])\n",
    "    nlp_fr = spacy.load('fr_core_news_sm')\n",
    "    nlp_en = spacy.load(\"en_core_web_sm\")\n",
    "    print(\"Installations terminées et modèles chargés avec succès.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Détecter la langue principale d'un texte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_and_translate(text):\n",
    "    language_mapping = {\n",
    "        'en': 'english',\n",
    "        'fr': 'french',\n",
    "        'es': 'spanish',\n",
    "        'it': 'italian',\n",
    "        'pt': 'portuguese',\n",
    "        'de': 'german',\n",
    "        'nl': 'dutch',\n",
    "        'ru': 'russian'\n",
    "    }\n",
    "    try:\n",
    "        detected_code, _ = langid.classify(text)  # Utilisation de langid\n",
    "        detected_language = language_mapping.get(detected_code, detected_code)\n",
    "\n",
    "        if detected_code == \"fr\":\n",
    "            return detected_language, text  # Pas de traduction\n",
    "\n",
    "        translated_lyrics = GoogleTranslator(source=detected_code, target='fr').translate(text)\n",
    "        return detected_language, translated_lyrics\n",
    "    except Exception as e:\n",
    "        return 'unknown', text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prétraitement des paroles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Prétraite le texte : suppression des caractères spéciaux, tokenisation,\n",
    "    suppression des stop words, stemming/lemmatisation et normalisation\n",
    "    \"\"\"\n",
    "\n",
    "    # Conversion en minuscules\n",
    "    text = text.lower()\n",
    "\n",
    "    # Normalisation Unicode\n",
    "    text = unicodedata.normalize('NFKD', text).encode('ASCII', 'ignore').decode('utf-8')\n",
    "\n",
    "    # Suppression des caractères spéciaux, des chiffres et des sauts de ligne\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', ' ', text)\n",
    "    text = re.sub(r'><', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    # Tokenisation\n",
    "    words = word_tokenize(text)\n",
    "\n",
    "    # Utilisation du paramètre language pour les stop words\n",
    "    stop_words = set(stopwords.words('french'))\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "\n",
    "    # Stemming avec la langue spécifiée\n",
    "    stemmer = SnowballStemmer('french')\n",
    "    words = [stemmer.stem(word) for word in words]\n",
    "\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse les sentiments d'une chanson complète"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sentiment(text):\n",
    "    \"\"\"\n",
    "    Analyse le sentiment d'un texte en français.\n",
    "    Retourne un score entre -1 (très négatif) et 1 (très positif).\n",
    "    \n",
    "    Args:\n",
    "        text (str): Texte en français à analyser\n",
    "        \n",
    "    Returns:\n",
    "        float: Score de sentiment entre -1 et 1\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Création d'un TextBlob avec le tagger et analyzer français\n",
    "        blob = TextBlob(text, pos_tagger=PatternTagger(), analyzer=PatternAnalyzer())\n",
    "        \n",
    "        # Récupération du score de polarité\n",
    "        polarity = blob.sentiment[0]\n",
    "        \n",
    "        # Normalisation du score entre -1 et 1\n",
    "        return float(polarity)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de l'analyse du sentiment: {e}\")\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_song_lyrics(title, lyrics):\n",
    "    \"\"\"\n",
    "    Analyse les sentiments d'une chanson complète\n",
    "    \"\"\"\n",
    "    # Nettoyage initial des lyrics (suppression des crochets et guillemets)\n",
    "    lyrics = re.sub(r'[\\[\\]\"]', '', lyrics)\n",
    "    \n",
    "    # Détection de la langue et traduction en francais\n",
    "    language, translated_lyrics = detect_and_translate(lyrics)\n",
    "    \n",
    "    # Prétraitement\n",
    "    cleaned_text = preprocess_text(translated_lyrics)\n",
    "    \n",
    "    # Analyse des sentiments\n",
    "    sentiment_score = analyze_sentiment(cleaned_text)\n",
    "    \n",
    "    # Classification du sentiment en fonction du score\n",
    "    if sentiment_score > 0.1:\n",
    "        sentiment = \"Positif\"\n",
    "    elif sentiment_score < -0.1:\n",
    "        sentiment = \"Négatif\"\n",
    "    else:\n",
    "        sentiment = \"Neutre\"\n",
    "    \n",
    "    return {\n",
    "        'titre': title,\n",
    "        'langue': language,\n",
    "        'score': sentiment_score,\n",
    "        'sentiment': sentiment,\n",
    "        'parole': cleaned_text\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse de chaque chanson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for song in base.to_dict(orient='records'):\n",
    "    result = analyze_song_lyrics(song['title'], song['paroles'])\n",
    "    results.append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Création d'un DataFrame pour afficher les résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(results)\n",
    "df_results = df_results[df_results['langue'] != \"unknown\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = f\"{artist.strip().replace(' ', '_')}_sentiments.xlsx\"\n",
    "df_results.to_excel(file_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "subprocess.run([\"streamlit\", \"run\", r\"3_app.py\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
